{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a9766d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis results for new data saved to New_Review_Results.json\n"
     ]
    }
   ],
   "source": [
    "# 가중합 예측\n",
    "import json\n",
    "import pandas as pd\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt\n",
    "from nltk import FreqDist\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "# 저장된 모델 로드\n",
    "with open('naive_bayes_classifier.pkl', 'rb') as model_file:\n",
    "    classifier = pickle.load(model_file)\n",
    "\n",
    "# 학습 때 사용한 단어 특징을 로드\n",
    "with open('word_features.pkl', 'rb') as wf_file:\n",
    "    word_features = pickle.load(wf_file)\n",
    "\n",
    "# Okt 객체 생성\n",
    "okt = Okt()\n",
    "\n",
    "# 특성 추출 함수 정의\n",
    "def preprocess_text(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = okt.pos(text, stem=True)\n",
    "    adjectives = [word for word, pos in words if pos == 'Adjective']\n",
    "    return adjectives\n",
    "\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[f'contains({word})'] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "# 새로운 데이터 예측 함수\n",
    "def predict_sentiment(review):\n",
    "    processed_review = preprocess_text(review)\n",
    "    features = document_features(processed_review)\n",
    "    predicted_sentiment = classifier.prob_classify(features)\n",
    "    sentiment_scores = {\n",
    "        'very positive': float(predicted_sentiment.prob('very positive')),\n",
    "        'positive': float(predicted_sentiment.prob('positive')),\n",
    "        'neutral': float(predicted_sentiment.prob('neutral')),\n",
    "        'negative': float(predicted_sentiment.prob('negative')),\n",
    "        'very negative': float(predicted_sentiment.prob('very negative'))\n",
    "    }\n",
    "    return sentiment_scores\n",
    "\n",
    "# input 로드하는 것 문장 단위도 가능.\n",
    "with open('Naver_Review1000.json', 'r', encoding='utf-8') as file:\n",
    "    new_data = json.load(file)\n",
    "\n",
    "# 예측 수행\n",
    "# 여기서 output 양식을 바꾸고 수행하면 될듯.\n",
    "results = []\n",
    "for item in new_data:\n",
    "    review_text = item['body']\n",
    "    predicted_scores = predict_sentiment(review_text)\n",
    "    result = {\n",
    "        'review': review_text,\n",
    "        # 'detailed_scores': predicted_scores, # 자세한 스코어\n",
    "        'predicted_score' :  (\n",
    "    predicted_scores['very positive'] * 5 +\n",
    "    predicted_scores['positive'] * 4 +\n",
    "    predicted_scores['neutral'] * 3 +\n",
    "    predicted_scores['negative'] * 2 +\n",
    "    predicted_scores['very negative'] * 1\n",
    ")\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# 결과를 JSON 파일로 저장 => 결과는 body, score 형식으로 나감\n",
    "with open('FINAL.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(results, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"Sentiment analysis results for new data saved to New_Review_Results.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90666de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis results for new data saved to New_Review_Results.json\n"
     ]
    }
   ],
   "source": [
    "# 그냥 1점 ~ 5점 분류\n",
    "import json\n",
    "import pandas as pd\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt\n",
    "from nltk import FreqDist\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "with open('naive_bayes_classifier.pkl', 'rb') as model_file:\n",
    "    classifier = pickle.load(model_file)\n",
    "\n",
    "with open('word_features.pkl', 'rb') as wf_file:\n",
    "    word_features = pickle.load(wf_file)\n",
    "\n",
    "def score_to_sentiment(score):\n",
    "    if score == 'very positive':\n",
    "        return 5\n",
    "    elif score == 'positive':\n",
    "        return 4\n",
    "    elif score == 'neutral':\n",
    "        return 3\n",
    "    elif score == 'negative':\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "    \n",
    "# Okt 객체 생성\n",
    "okt = Okt()\n",
    "\n",
    "# 특성 추출 함수 정의\n",
    "def preprocess_text(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = okt.pos(text, stem=True)\n",
    "    adjectives = [word for word, pos in words if pos == 'Adjective']\n",
    "    return adjectives\n",
    "\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[f'contains({word})'] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "# 새로운 데이터 예측 함수\n",
    "def predict_sentiment(review):\n",
    "    processed_review = preprocess_text(review)\n",
    "    features = document_features(processed_review)\n",
    "    predicted_sentiment = classifier.prob_classify(features)\n",
    "    sentiment_scores = {\n",
    "        'very positive': float(predicted_sentiment.prob('very positive')),\n",
    "        'positive': float(predicted_sentiment.prob('positive')),\n",
    "        'neutral': float(predicted_sentiment.prob('neutral')),\n",
    "        'negative': float(predicted_sentiment.prob('negative')),\n",
    "        'very negative': float(predicted_sentiment.prob('very negative'))\n",
    "    }\n",
    "    predicted_scores = max(sentiment_scores,key=sentiment_scores.get)\n",
    "    return predicted_scores\n",
    "\n",
    "# input 로드하는 것 문장 단위도 가능.\n",
    "with open('Naver_Review1000.json', 'r', encoding='utf-8') as file:\n",
    "    new_data = json.load(file)\n",
    "\n",
    "# 예측 수행\n",
    "# 여기서 output 양식을 바꾸고 수행하면 될듯.\n",
    "results = []\n",
    "for item in new_data:\n",
    "    review_text = item['body']\n",
    "    predicted_scores = predict_sentiment(review_text)\n",
    "    result = {\n",
    "        'review': review_text,\n",
    "        # 'detailed_scores': predicted_scores, # 자세한 스코어\n",
    "        'predicted_score' :  score_to_sentiment(predicted_scores)\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# 결과를 JSON 파일로 저장 => 결과는 body, score 형식으로 나감\n",
    "with open('FINAL.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(results, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"결과가 FINAL에 저장되었음.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624bd120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
